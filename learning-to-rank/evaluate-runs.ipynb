{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded\n",
    "from tira.rest_api_client import Client\n",
    "from ir_measures import nDCG\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = {\n",
    "    # 'longeval-train-20230513-training': 'train_2023', \n",
    "    # 'longeval-heldout-20230513-training': 'WT',\n",
    "    # 'longeval-short-july-20230513-training': 'ST',\n",
    "    # 'longeval-long-september-20230513-training': 'LT',\n",
    "    'longeval-2023-01-20240423-training': 'train_2024',\n",
    "    # 'longeval-2023-06-20240418-training': 'lag6',\n",
    "    # 'longeval-2023-08-20240418-training': 'lag8',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longeval-2023-01-20240423-training\n",
      "           name  nDCG@10   nDCG  nDCG(judged_only=True)@10  nDCG(judged_only=True)\n",
      "0          BM25    0.197  0.319                      0.448                   0.482\n",
      "1  BM25 + LMART    0.284  0.379                      0.483                   0.502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, run_suffix in DATASETS.items():\n",
    "    dataset = pt.get_dataset(f'irds:ir-benchmarks/{dataset_name}')\n",
    "\n",
    "    bm25 = tira.pt.from_submission('ir-benchmarks/tira-ir-starter/BM25 Re-Rank (tira-ir-starter-pyterrier)', dataset)\n",
    "    ltr = pt.io.read_results(f'../runs/ows_ltr/ows_ltr.{run_suffix}')\n",
    "\n",
    "    print(dataset_name)\n",
    "    print(pt.Experiment(\n",
    "        [bm25, ltr],\n",
    "        # dataset.get_topics(variant='query'),\n",
    "        # dataset.get_qrels(variant='relevance'),\n",
    "        pd.read_csv('../splits/2024/topics_val.csv'),\n",
    "        pd.read_csv('../splits/2024/qrels_val.csv'),\n",
    "        eval_metrics=[nDCG@10, nDCG, nDCG(judged_only=True)@10, nDCG(judged_only=True)],\n",
    "        names=['BM25', 'BM25 + LMART']\n",
    "    ).round(3))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
